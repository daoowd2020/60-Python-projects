{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daoowd2020/60-Python-projects/blob/main/Sarcasm_Detection_dawood_after_feutcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzodQy_pJlWH"
      },
      "source": [
        "# DPhi - NLP Bootcamp Datathon - Sarcasm Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NT8nygynJlWQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk as nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hUGU1ptEJlWT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCqCHFx6JlWT"
      },
      "source": [
        "# 1- Introduction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfDjw9FgJlWU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP9hBnxOJlWV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du3rkZ2dJlWV"
      },
      "source": [
        "# 1.1 Background "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVbJau5kJlWX"
      },
      "source": [
        "# 1.2 About The data sets which will be used "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TogCS0bVJlWY"
      },
      "source": [
        "# 2. Understanding the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZO9KbLZOJlWZ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ttIXyDFJlWa"
      },
      "source": [
        "### Importing The required python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mnwlCrdr9V6g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk as nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAYlihrXJlWd"
      },
      "source": [
        "## 2.1 Reading & Loading data sets¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "uNwNXCjL9pkz",
        "outputId": "1ec8188e-262b-4de4-b315-3d162901dcc0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5ffa30b60f4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://drive.google.com/file/d/1PLELR7dShBtVa35GqDLKvlheVej-cWrj/view?usp=sharing/train_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://drive.google.com/file/d/1PNsh6UnIC7AnPnqQXKUoLAZ2uOuLq1NV/view?usp=sharing/test_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
          ]
        }
      ],
      "source": [
        "df_train = pd.read_csv(\"https://drive.google.com/file/d/1PLELR7dShBtVa35GqDLKvlheVej-cWrj/view?usp=sharing/train_data.csv\")\n",
        "df_test = pd.read_csv(\"https://drive.google.com/file/d/1PNsh6UnIC7AnPnqQXKUoLAZ2uOuLq1NV/view?usp=sharing/Test_Data.csv\")\n",
        "df_train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDeSYWOvJlWh"
      },
      "source": [
        "## 2.2 Exploring the data set¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LisLS23JlWh",
        "outputId": "a3115326-f1ae-42f1-9201-70db84092b98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(44262, 2)"
            ]
          },
          "execution_count": 929,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ICqV-L0JlWj",
        "outputId": "781fae7a-12d1-4cfe-af3a-40f91d90ec1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 44262 entries, 0 to 44261\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   headline      44262 non-null  object\n",
            " 1   is_sarcastic  44262 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 691.7+ KB\n"
          ]
        }
      ],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yKAzTpLJlWk",
        "outputId": "f5e42b72-8fe8-47df-a2e2-eb88b2f2cfa6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>44262.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.458723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.498299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       is_sarcastic\n",
              "count  44262.000000\n",
              "mean       0.458723\n",
              "std        0.498299\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        1.000000\n",
              "max        1.000000"
            ]
          },
          "execution_count": 931,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atHuTagjJlWk",
        "outputId": "e7eb1739-520e-4643-883f-95aaf5684e12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44262"
            ]
          },
          "execution_count": 932,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.value_counts().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYJ5LSpSJlWl",
        "outputId": "41ccf6e1-2785-4ff2-dd0e-78037e0b374f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "headline  is_sarcastic\n",
              "False     False           44262\n",
              "dtype: int64"
            ]
          },
          "execution_count": 933,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.isnull().value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjAQ9zLWJlWm",
        "outputId": "81b5181b-f170-43d9-86e4-8e9295c5c9ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    23958\n",
              "1    20304\n",
              "Name: is_sarcastic, dtype: int64"
            ]
          },
          "execution_count": 934,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.is_sarcastic.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke4LzY8FJlWm",
        "outputId": "9c609c09-0b62-4915-854c-f4bb87887387"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.541277\n",
              "1    0.458723\n",
              "Name: is_sarcastic, dtype: float64"
            ]
          },
          "execution_count": 935,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.is_sarcastic.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "SQzXB_iI9xG1",
        "outputId": "84c5c24d-06a9-4531-841c-9e2d87cdd5ab"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#sns.countplot(df['is_sarcastic'])\n",
        "df_train.is_sarcastic.value_counts(normalize=True).plot.pie()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8NJIy0kJlWn"
      },
      "source": [
        "## 3. Data Preparation-Pre-processing text data¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3AFG5B4JlWo"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "string.punctuation\n",
        "punct= string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJQZVCx3JlWo"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "#\\W+ regex, indicates that it will split wherever it sees one or more non-word characters.\n",
        "#So that'll split on white spaces, special characters, anything like that.\n",
        "\n",
        "text='I love NLP,will use python in our code.'\n",
        "tokens = re.split('\\W+', text)\n",
        "tokens\n",
        "from nltk.tokenize import word_tokenize\n",
        "#import nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stopwords_En = nltk.corpus.stopwords.words('english')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZW9jtzWJlWp"
      },
      "outputs": [],
      "source": [
        "### Create function to remove punctuation, tokenize, remove stopwords, and stem\n",
        "\n",
        "def clean_text(text):\n",
        "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "     #tokens = re.split('\\W+', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    #text = \" \".join([ps.stem(word) for word in tokens if word not in stopwords_En])\n",
        "    text = ' '.join([wn.lemmatize(word) for word in text.split()])\n",
        "    \n",
        "    # stopwords removal\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    \n",
        "    return text\n",
        "df_train=df_train[['headline','is_sarcastic']]\n",
        "df_train['cleaned_text'] = df_train['headline'].apply(lambda x: clean_text(x))\n",
        "\n",
        "df_test=df_test[['headline']]\n",
        "df_test['cleaned_text'] = df_test['headline'].apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGYQihjwJlWp",
        "outputId": "ed761b55-dc78-4f20-e6a7-46f99db5784c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
              "      <td>1</td>\n",
              "      <td>supreme court vote 72 legalize worldly vice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hungover man horrified to learn he made dozens...</td>\n",
              "      <td>1</td>\n",
              "      <td>hungover man horrified learn made dozen plan l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>emily's list founder: women are the 'problem s...</td>\n",
              "      <td>0</td>\n",
              "      <td>emilys list founder woman problem solver congress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>send your kids back to school with confidence</td>\n",
              "      <td>0</td>\n",
              "      <td>send kid back school confidence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>watch: experts talk pesticides and health</td>\n",
              "      <td>0</td>\n",
              "      <td>watch expert talk pesticide health</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic  \\\n",
              "0  supreme court votes 7-2 to legalize all worldl...             1   \n",
              "1  hungover man horrified to learn he made dozens...             1   \n",
              "2  emily's list founder: women are the 'problem s...             0   \n",
              "3      send your kids back to school with confidence             0   \n",
              "4          watch: experts talk pesticides and health             0   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0        supreme court vote 72 legalize worldly vice  \n",
              "1  hungover man horrified learn made dozen plan l...  \n",
              "2  emilys list founder woman problem solver congress  \n",
              "3                    send kid back school confidence  \n",
              "4                 watch expert talk pesticide health  "
            ]
          },
          "execution_count": 940,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDtB4mF9JlWq"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "ps = nltk.PorterStemmer()\n",
        "def normalize_document(doc):\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
        "   # doc = re.sub(r'[^a-zA-Z]',r' ', document)\n",
        "    doc = re.sub(r'nbsp', r'', doc)\n",
        "    doc = re.sub(' +', ' ', doc)\n",
        "    doc = doc.lower()\n",
        "    doc = doc.strip()\n",
        "    # tokenize document\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    # filter stopwords out of document\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    filtered_tokens= [wn.lemmatize(word) for word in filtered_tokens]\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    return doc\n",
        "\n",
        "corpus1=df_train['headline']\n",
        "corpus2=df_test['headline']\n",
        "normalize_corpus1 = np.vectorize(normalize_document)\n",
        "normalize_corpus2 = np.vectorize(normalize_document)\n",
        "new_headline1 = normalize_corpus(corpus1)\n",
        "new_headline2 = normalize_corpus(corpus2)\n",
        "#norm_corpus\n",
        "df_train['new_headline'] = df_train['headline'].apply(lambda x: normalize_document(x.lower()))\n",
        "df_test['new_headline'] = df_test['headline'].apply(lambda x: normalize_document(x.lower()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOZD4qMzJlWs",
        "outputId": "a839a9c2-9ff1-4cc3-d56a-a4f349d6a0fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>new_headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
              "      <td>1</td>\n",
              "      <td>supreme court vote 72 legalize worldly vice</td>\n",
              "      <td>supreme court vote 72 legalize worldly vice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hungover man horrified to learn he made dozens...</td>\n",
              "      <td>1</td>\n",
              "      <td>hungover man horrified learn made dozen plan l...</td>\n",
              "      <td>hungover man horrified learn made dozen plan l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>emily's list founder: women are the 'problem s...</td>\n",
              "      <td>0</td>\n",
              "      <td>emilys list founder woman problem solver congress</td>\n",
              "      <td>emilys list founder woman problem solver congress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>send your kids back to school with confidence</td>\n",
              "      <td>0</td>\n",
              "      <td>send kid back school confidence</td>\n",
              "      <td>send kid back school confidence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>watch: experts talk pesticides and health</td>\n",
              "      <td>0</td>\n",
              "      <td>watch expert talk pesticide health</td>\n",
              "      <td>watch expert talk pesticide health</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic  \\\n",
              "0  supreme court votes 7-2 to legalize all worldl...             1   \n",
              "1  hungover man horrified to learn he made dozens...             1   \n",
              "2  emily's list founder: women are the 'problem s...             0   \n",
              "3      send your kids back to school with confidence             0   \n",
              "4          watch: experts talk pesticides and health             0   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0        supreme court vote 72 legalize worldly vice   \n",
              "1  hungover man horrified learn made dozen plan l...   \n",
              "2  emilys list founder woman problem solver congress   \n",
              "3                    send kid back school confidence   \n",
              "4                 watch expert talk pesticide health   \n",
              "\n",
              "                                        new_headline  \n",
              "0        supreme court vote 72 legalize worldly vice  \n",
              "1  hungover man horrified learn made dozen plan l...  \n",
              "2  emilys list founder woman problem solver congress  \n",
              "3                    send kid back school confidence  \n",
              "4                 watch expert talk pesticide health  "
            ]
          },
          "execution_count": 942,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag84jDb2JlWs",
        "outputId": "c17b82bf-3fd6-4a85-9355-eca1debe5451"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>new_headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>area stand-up comedian questions the deal with...</td>\n",
              "      <td>area standup comedian question deal drivethru ...</td>\n",
              "      <td>area standup comedian question deal drivethru ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dozens of glowing exit signs mercilessly taunt...</td>\n",
              "      <td>dozen glowing exit sign mercilessly taunt mult...</td>\n",
              "      <td>dozen glowing exit sign mercilessly taunt mult...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>perfect response to heckler somewhere in prop ...</td>\n",
              "      <td>perfect response heckler somewhere prop comedi...</td>\n",
              "      <td>perfect response heckler somewhere prop comedi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gop prays for ossoff lossoff</td>\n",
              "      <td>gop prays ossoff lossoff</td>\n",
              "      <td>gop prays ossoff lossoff</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>trevor noah says the scary truth about trump's...</td>\n",
              "      <td>trevor noah say scary truth trump rumored love...</td>\n",
              "      <td>trevor noah say scary truth trump rumored love...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  \\\n",
              "0  area stand-up comedian questions the deal with...   \n",
              "1  dozens of glowing exit signs mercilessly taunt...   \n",
              "2  perfect response to heckler somewhere in prop ...   \n",
              "3                       gop prays for ossoff lossoff   \n",
              "4  trevor noah says the scary truth about trump's...   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0  area standup comedian question deal drivethru ...   \n",
              "1  dozen glowing exit sign mercilessly taunt mult...   \n",
              "2  perfect response heckler somewhere prop comedi...   \n",
              "3                           gop prays ossoff lossoff   \n",
              "4  trevor noah say scary truth trump rumored love...   \n",
              "\n",
              "                                        new_headline  \n",
              "0  area standup comedian question deal drivethru ...  \n",
              "1  dozen glowing exit sign mercilessly taunt mult...  \n",
              "2  perfect response heckler somewhere prop comedi...  \n",
              "3                           gop prays ossoff lossoff  \n",
              "4  trevor noah say scary truth trump rumored love...  "
            ]
          },
          "execution_count": 943,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t134LklpJlWt",
        "outputId": "1ebc315f-6c95-4107-d8fc-901c8a2a3948"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "headline        0\n",
              "cleaned_text    0\n",
              "new_headline    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 944,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyjPZKBgJlWu"
      },
      "source": [
        "# 4. Vectorizing text data TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozincVcKJlWu"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "#tfidf = TfidfVectorizer(min_df=1)\n",
        "tfidf = TfidfVectorizer( ngram_range=(1,1))\n",
        "features_tfidf = tfidf.fit_transform(df_train['cleaned_text'])\n",
        "print(features_tfidf.shape)\n",
        "print('Sparse Matrix :\\n', features_tfidf)\n",
        "features_tfidf = pd.DataFrame(features_tfidf.toarray())\n",
        "features_tfidf.columns = tfidf.get_feature_names()\n",
        "features_tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfuOG1H5JlWu",
        "outputId": "1187125c-a9da-44e7-d496-c918a25b00a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(44262, 25192)\n",
            "Sparse Matrix :\n",
            "   (0, 24063)\t0.3653518284793476\n",
            "  (0, 24880)\t0.4921008171504763\n",
            "  (0, 13002)\t0.4317780888087405\n",
            "  (0, 672)\t0.4240221508871343\n",
            "  (0, 24218)\t0.29805611004469873\n",
            "  (0, 5477)\t0.2813309927817895\n",
            "  (0, 21972)\t0.3002384927583164\n",
            "  (1, 15358)\t0.3034613181724768\n",
            "  (1, 12867)\t0.28172864312909685\n",
            "  (1, 16979)\t0.27709966494777993\n",
            "  (1, 7068)\t0.3581580234620887\n",
            "  (1, 13612)\t0.2998915046754105\n",
            "  (1, 12959)\t0.3595344153352317\n",
            "  (1, 10948)\t0.3980765126804223\n",
            "  (1, 13727)\t0.19070583225115964\n",
            "  (1, 11107)\t0.4576519104514653\n",
            "  (2, 5112)\t0.30299181479990983\n",
            "  (2, 21000)\t0.48728598752412705\n",
            "  (2, 17637)\t0.31810829550356046\n",
            "  (2, 24822)\t0.2143992178723411\n",
            "  (2, 9056)\t0.4076536422079261\n",
            "  (2, 13244)\t0.3306645803718914\n",
            "  (2, 7595)\t0.49806410984584526\n",
            "  (3, 5076)\t0.5618642544312047\n",
            "  (3, 19769)\t0.3796861863869382\n",
            "  :\t:\n",
            "  (44258, 3848)\t0.4303976044427548\n",
            "  (44258, 23965)\t0.38948103315843635\n",
            "  (44258, 19685)\t0.2400718606672251\n",
            "  (44258, 2560)\t0.3676448256040375\n",
            "  (44258, 22979)\t0.37059340040920413\n",
            "  (44258, 13727)\t0.20189272205812905\n",
            "  (44259, 7470)\t0.4857924594516143\n",
            "  (44259, 17086)\t0.4033855320226301\n",
            "  (44259, 5176)\t0.3924650767441643\n",
            "  (44259, 18153)\t0.3418037778945084\n",
            "  (44259, 6963)\t0.23947472022815572\n",
            "  (44259, 17793)\t0.33756620733293513\n",
            "  (44259, 10822)\t0.35666816051855227\n",
            "  (44259, 23158)\t0.17865015297733924\n",
            "  (44260, 15838)\t0.5678698270937518\n",
            "  (44260, 9788)\t0.5524569139350931\n",
            "  (44260, 18362)\t0.4073698661981415\n",
            "  (44260, 11981)\t0.4542741571292976\n",
            "  (44261, 24599)\t0.4359189752165128\n",
            "  (44261, 23406)\t0.46093407825077287\n",
            "  (44261, 13854)\t0.33699798843041345\n",
            "  (44261, 21559)\t0.34893582727207295\n",
            "  (44261, 2983)\t0.42468509573531327\n",
            "  (44261, 1801)\t0.22420855758447322\n",
            "  (44261, 13418)\t0.36271705082513356\n"
          ]
        },
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 8.31 GiB for an array with shape (44262, 25192) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4324/3606605123.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sparse Matrix :\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mfeatures_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mfeatures_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfeatures_tfidf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.31 GiB for an array with shape (44262, 25192) and data type float64"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "#tfidf = TfidfVectorizer(min_df=1)\n",
        "tfidf = TfidfVectorizer( ngram_range=(1,1))\n",
        "features_tfidf = tfidf.fit_transform(df_train['cleaned_text'])\n",
        "print(features_tfidf.shape)\n",
        "print('Sparse Matrix :\\n', features_tfidf)\n",
        "features_tfidf = pd.DataFrame(features_tfidf.toarray())\n",
        "features_tfidf.columns = tfidf.get_feature_names()\n",
        "features_tfidf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZAml7F2JlWv",
        "outputId": "0b0db769-3f23-4ba2-8b43-01bc881a1848"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "head not found",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4324/1171410422.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: head not found"
          ]
        }
      ],
      "source": [
        "features_tfidf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaH76CGGJlWv"
      },
      "source": [
        "# 5. Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRJv6gPRJlWw"
      },
      "source": [
        "df_train_sentiment_features = df_train['new_headline'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
        "df_train['Polarity'] = [obj.polarity for obj in df_train_sentiment_features.values]\n",
        "df_train['Subjectivity'] = [obj.subjectivity for obj in df_train_sentiment_features.values]\n",
        "\n",
        "df_test_sentiment_features = df_test['headline'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
        "df_test['Polarity'] = [obj.polarity for obj in df_test_sentiment_features.values]\n",
        "df_test['Subjectivity'] = [obj.subjectivity for obj in df_test_sentiment_features.values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksneb1YAJlWw",
        "outputId": "a160f1e8-1b82-4b81-a87a-7c4a3ebb5cae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>new_headline</th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
              "      <td>1</td>\n",
              "      <td>supreme court vote 72 legalize worldly vice</td>\n",
              "      <td>supreme court vote 72 legalize worldly vice</td>\n",
              "      <td>45</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hungover man horrified to learn he made dozens...</td>\n",
              "      <td>1</td>\n",
              "      <td>hungover man horrified learn made dozen plan l...</td>\n",
              "      <td>hungover man horrified learn made dozen plan l...</td>\n",
              "      <td>55</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>emily's list founder: women are the 'problem s...</td>\n",
              "      <td>0</td>\n",
              "      <td>emilys list founder woman problem solver congress</td>\n",
              "      <td>emilys list founder woman problem solver congress</td>\n",
              "      <td>56</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>send your kids back to school with confidence</td>\n",
              "      <td>0</td>\n",
              "      <td>send kid back school confidence</td>\n",
              "      <td>send kid back school confidence</td>\n",
              "      <td>38</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>watch: experts talk pesticides and health</td>\n",
              "      <td>0</td>\n",
              "      <td>watch expert talk pesticide health</td>\n",
              "      <td>watch expert talk pesticide health</td>\n",
              "      <td>36</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic  \\\n",
              "0  supreme court votes 7-2 to legalize all worldl...             1   \n",
              "1  hungover man horrified to learn he made dozens...             1   \n",
              "2  emily's list founder: women are the 'problem s...             0   \n",
              "3      send your kids back to school with confidence             0   \n",
              "4          watch: experts talk pesticides and health             0   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0        supreme court vote 72 legalize worldly vice   \n",
              "1  hungover man horrified learn made dozen plan l...   \n",
              "2  emilys list founder woman problem solver congress   \n",
              "3                    send kid back school confidence   \n",
              "4                 watch expert talk pesticide health   \n",
              "\n",
              "                                        new_headline  body_len  punct%  \n",
              "0        supreme court vote 72 legalize worldly vice        45     2.2  \n",
              "1  hungover man horrified learn made dozen plan l...        55     0.0  \n",
              "2  emilys list founder woman problem solver congress        56     7.1  \n",
              "3                    send kid back school confidence        38     0.0  \n",
              "4                 watch expert talk pesticide health        36     2.8  "
            ]
          },
          "execution_count": 900,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "def count_punct(text):\n",
        "    count = sum([1 for char in text if char in string.punctuation])\n",
        "    return round( count/(len(text) - text.count(\" \")),3)*100\n",
        "\n",
        "df_train['body_len'] = df_train['headline'].apply(lambda x: len(x) - x.count(\" \"))\n",
        "df_train['punct%'] = df_train['headline'].apply(lambda x: count_punct(x))\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOjcI3EiJlWw"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "df_train['char_count'] = df_train['headline'].apply(len)\n",
        "df_train['word_count'] = df_train['headline'].apply(lambda x: len(x.split()))\n",
        "df_train['word_density'] = df_train['char_count'] / (df_train['word_count']+1)\n",
        "df_train['punctuation_count'] = df_train['headline'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
        "df_train['title_word_count'] = df_train['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
        "df_train['upper_case_word_count'] = df_train['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbtCaEPeJlWx"
      },
      "outputs": [],
      "source": [
        "df_test['char_count'] = df_test['headline'].apply(len)\n",
        "df_test['word_count'] = df_test['headline'].apply(lambda x: len(x.split()))\n",
        "df_test['word_density'] = df_test['char_count'] / (df_test['word_count']+1)\n",
        "df_test['punctuation_count'] = df_test['headline'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
        "df_test['title_word_count'] = df_test['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
        "df_test['upper_case_word_count'] = df_test['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ik2Mr71JlW4",
        "outputId": "d7ea983e-0a01-47d1-b99f-58f6140dd83f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>new_headline</th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>title_word_count</th>\n",
              "      <th>upper_case_word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
              "      <td>1</td>\n",
              "      <td>supreme court vote 72 legalize worldly vice</td>\n",
              "      <td>supreme court vote 72 legalize worldly vice</td>\n",
              "      <td>45</td>\n",
              "      <td>2.2</td>\n",
              "      <td>53</td>\n",
              "      <td>9</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hungover man horrified to learn he made dozens...</td>\n",
              "      <td>1</td>\n",
              "      <td>hungover man horrified learn made dozen plan l...</td>\n",
              "      <td>hungover man horrified learn made dozen plan l...</td>\n",
              "      <td>55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66</td>\n",
              "      <td>12</td>\n",
              "      <td>5.076923</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>emily's list founder: women are the 'problem s...</td>\n",
              "      <td>0</td>\n",
              "      <td>emilys list founder woman problem solver congress</td>\n",
              "      <td>emilys list founder woman problem solver congress</td>\n",
              "      <td>56</td>\n",
              "      <td>7.1</td>\n",
              "      <td>65</td>\n",
              "      <td>10</td>\n",
              "      <td>5.909091</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>send your kids back to school with confidence</td>\n",
              "      <td>0</td>\n",
              "      <td>send kid back school confidence</td>\n",
              "      <td>send kid back school confidence</td>\n",
              "      <td>38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45</td>\n",
              "      <td>8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>watch: experts talk pesticides and health</td>\n",
              "      <td>0</td>\n",
              "      <td>watch expert talk pesticide health</td>\n",
              "      <td>watch expert talk pesticide health</td>\n",
              "      <td>36</td>\n",
              "      <td>2.8</td>\n",
              "      <td>41</td>\n",
              "      <td>6</td>\n",
              "      <td>5.857143</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic  \\\n",
              "0  supreme court votes 7-2 to legalize all worldl...             1   \n",
              "1  hungover man horrified to learn he made dozens...             1   \n",
              "2  emily's list founder: women are the 'problem s...             0   \n",
              "3      send your kids back to school with confidence             0   \n",
              "4          watch: experts talk pesticides and health             0   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0        supreme court vote 72 legalize worldly vice   \n",
              "1  hungover man horrified learn made dozen plan l...   \n",
              "2  emilys list founder woman problem solver congress   \n",
              "3                    send kid back school confidence   \n",
              "4                 watch expert talk pesticide health   \n",
              "\n",
              "                                        new_headline  body_len  punct%  \\\n",
              "0        supreme court vote 72 legalize worldly vice        45     2.2   \n",
              "1  hungover man horrified learn made dozen plan l...        55     0.0   \n",
              "2  emilys list founder woman problem solver congress        56     7.1   \n",
              "3                    send kid back school confidence        38     0.0   \n",
              "4                 watch expert talk pesticide health        36     2.8   \n",
              "\n",
              "   char_count  word_count  word_density  punctuation_count  title_word_count  \\\n",
              "0          53           9      5.300000                  1                 0   \n",
              "1          66          12      5.076923                  0                 0   \n",
              "2          65          10      5.909091                  4                 0   \n",
              "3          45           8      5.000000                  0                 0   \n",
              "4          41           6      5.857143                  1                 0   \n",
              "\n",
              "   upper_case_word_count  \n",
              "0                      0  \n",
              "1                      0  \n",
              "2                      0  \n",
              "3                      0  \n",
              "4                      0  "
            ]
          },
          "execution_count": 903,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evw2bTl2JlW4",
        "outputId": "bf48edad-3588-4dd7-f7a8-8f58af4f6562"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>title_word_count</th>\n",
              "      <th>upper_case_word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>44262.000000</td>\n",
              "      <td>44262.000000</td>\n",
              "      <td>44262.000000</td>\n",
              "      <td>44262.000000</td>\n",
              "      <td>44262.000000</td>\n",
              "      <td>44262.000000</td>\n",
              "      <td>44262.000000</td>\n",
              "      <td>44262.0</td>\n",
              "      <td>44262.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.458723</td>\n",
              "      <td>52.668768</td>\n",
              "      <td>2.087203</td>\n",
              "      <td>61.618860</td>\n",
              "      <td>9.947856</td>\n",
              "      <td>5.629592</td>\n",
              "      <td>1.094460</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.498299</td>\n",
              "      <td>17.212947</td>\n",
              "      <td>2.488937</td>\n",
              "      <td>20.158453</td>\n",
              "      <td>3.303905</td>\n",
              "      <td>0.824368</td>\n",
              "      <td>1.302318</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>776.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>926.000000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       is_sarcastic      body_len        punct%    char_count    word_count  \\\n",
              "count  44262.000000  44262.000000  44262.000000  44262.000000  44262.000000   \n",
              "mean       0.458723     52.668768      2.087203     61.618860      9.947856   \n",
              "std        0.498299     17.212947      2.488937     20.158453      3.303905   \n",
              "min        0.000000      6.000000      0.000000      7.000000      2.000000   \n",
              "25%        0.000000     41.000000      0.000000     48.000000      8.000000   \n",
              "50%        0.000000     53.000000      1.600000     62.000000     10.000000   \n",
              "75%        1.000000     63.000000      3.400000     74.000000     12.000000   \n",
              "max        1.000000    776.000000     30.000000    926.000000    151.000000   \n",
              "\n",
              "       word_density  punctuation_count  title_word_count  \\\n",
              "count  44262.000000       44262.000000           44262.0   \n",
              "mean       5.629592           1.094460               0.0   \n",
              "std        0.824368           1.302318               0.0   \n",
              "min        2.333333           0.000000               0.0   \n",
              "25%        5.083333           0.000000               0.0   \n",
              "50%        5.600000           1.000000               0.0   \n",
              "75%        6.142857           2.000000               0.0   \n",
              "max       12.000000          28.000000               0.0   \n",
              "\n",
              "       upper_case_word_count  \n",
              "count                44262.0  \n",
              "mean                     0.0  \n",
              "std                      0.0  \n",
              "min                      0.0  \n",
              "25%                      0.0  \n",
              "50%                      0.0  \n",
              "75%                      0.0  \n",
              "max                      0.0  "
            ]
          },
          "execution_count": 904,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78guuFr_JlW5"
      },
      "source": [
        "## 5.4 Rescaling the Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsJgVlZoJlW5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHJcrp65JlW5"
      },
      "outputs": [],
      "source": [
        "num_vars = ['body_len','punct%','word_count','word_density','punctuation_count','title_word_count','upper_case_word_count']\n",
        "df_train[num_vars]= scaler.fit_transform(df_train[num_vars])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrYqpWgdJlW5",
        "outputId": "dc150de2-cb3a-4a6e-d3dc-4c5579126362"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>title_word_count</th>\n",
              "      <th>upper_case_word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.050649</td>\n",
              "      <td>0.073333</td>\n",
              "      <td>0.046980</td>\n",
              "      <td>0.306897</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.063636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.067114</td>\n",
              "      <td>0.283820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.064935</td>\n",
              "      <td>0.236667</td>\n",
              "      <td>0.053691</td>\n",
              "      <td>0.369906</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.041558</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040268</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.038961</td>\n",
              "      <td>0.093333</td>\n",
              "      <td>0.026846</td>\n",
              "      <td>0.364532</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   body_len    punct%  word_count  word_density  punctuation_count  \\\n",
              "0  0.050649  0.073333    0.046980      0.306897           0.035714   \n",
              "1  0.063636  0.000000    0.067114      0.283820           0.000000   \n",
              "2  0.064935  0.236667    0.053691      0.369906           0.142857   \n",
              "3  0.041558  0.000000    0.040268      0.275862           0.000000   \n",
              "4  0.038961  0.093333    0.026846      0.364532           0.035714   \n",
              "\n",
              "   title_word_count  upper_case_word_count  \n",
              "0               0.0                    0.0  \n",
              "1               0.0                    0.0  \n",
              "2               0.0                    0.0  \n",
              "3               0.0                    0.0  \n",
              "4               0.0                    0.0  "
            ]
          },
          "execution_count": 907,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train[num_vars].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7WkA6toJlW6"
      },
      "source": [
        "## Model bulding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPvn1ciiJlW6"
      },
      "source": [
        "## 6.2 Final data frame to use it in the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul7RE7JzJlW6"
      },
      "outputs": [],
      "source": [
        "target= df_train['is_sarcastic']\n",
        "\n",
        "#final_df=df_train.drop(['headline', 'new_headline', 'cleaned_text','is_sarcastic'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkQJEQ_zJlW6"
      },
      "outputs": [],
      "source": [
        "x = df_train['new_headline']\n",
        "#df_train=df_train.drop['is_sarcastic','cleaned_text','headline']\n",
        "#x2= df_test['new_headline2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjPpxsQQJlW6"
      },
      "outputs": [],
      "source": [
        "# Create a bag of words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = TfidfVectorizer()\n",
        "#cv=CountVectorizer()\n",
        "bow1 = cv.fit_transform(x)\n",
        "#bow = np.array(bow.todense())\n",
        "final_df=df_train.drop(['headline', 'new_headline', 'cleaned_text','is_sarcastic'], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "robOHm3XJlW7"
      },
      "outputs": [],
      "source": [
        "#target= df_train['is_sarcastic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2ujcpB0JlW7",
        "outputId": "7f7b735c-3ca7-41b0-8259-47f6e428e59a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>title_word_count</th>\n",
              "      <th>upper_case_word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.050649</td>\n",
              "      <td>0.073333</td>\n",
              "      <td>53</td>\n",
              "      <td>0.046980</td>\n",
              "      <td>0.306897</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.063636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66</td>\n",
              "      <td>0.067114</td>\n",
              "      <td>0.283820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.064935</td>\n",
              "      <td>0.236667</td>\n",
              "      <td>65</td>\n",
              "      <td>0.053691</td>\n",
              "      <td>0.369906</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.041558</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45</td>\n",
              "      <td>0.040268</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.038961</td>\n",
              "      <td>0.093333</td>\n",
              "      <td>41</td>\n",
              "      <td>0.026846</td>\n",
              "      <td>0.364532</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   body_len    punct%  char_count  word_count  word_density  \\\n",
              "0  0.050649  0.073333          53    0.046980      0.306897   \n",
              "1  0.063636  0.000000          66    0.067114      0.283820   \n",
              "2  0.064935  0.236667          65    0.053691      0.369906   \n",
              "3  0.041558  0.000000          45    0.040268      0.275862   \n",
              "4  0.038961  0.093333          41    0.026846      0.364532   \n",
              "\n",
              "   punctuation_count  title_word_count  upper_case_word_count  \n",
              "0           0.035714               0.0                    0.0  \n",
              "1           0.000000               0.0                    0.0  \n",
              "2           0.142857               0.0                    0.0  \n",
              "3           0.000000               0.0                    0.0  \n",
              "4           0.035714               0.0                    0.0  "
            ]
          },
          "execution_count": 912,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "780dyr1tJlW7"
      },
      "outputs": [],
      "source": [
        "final_df = pd.concat([final_df, pd.DataFrame(bow1)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odnGqKHhJlW7",
        "outputId": "c28650eb-0146-4b90-e234-4ab3ba0b6d2b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>title_word_count</th>\n",
              "      <th>upper_case_word_count</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.050649</td>\n",
              "      <td>0.073333</td>\n",
              "      <td>53</td>\n",
              "      <td>0.046980</td>\n",
              "      <td>0.306897</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0, 24068)\\t0.3653518284793476\\n  (0, 24886)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.063636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66</td>\n",
              "      <td>0.067114</td>\n",
              "      <td>0.283820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0, 15364)\\t0.3034613181724768\\n  (0, 12877)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.064935</td>\n",
              "      <td>0.236667</td>\n",
              "      <td>65</td>\n",
              "      <td>0.053691</td>\n",
              "      <td>0.369906</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0, 5116)\\t0.30299181479990983\\n  (0, 21005)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.041558</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45</td>\n",
              "      <td>0.040268</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0, 5080)\\t0.5618642544312047\\n  (0, 19776)\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.038961</td>\n",
              "      <td>0.093333</td>\n",
              "      <td>41</td>\n",
              "      <td>0.026846</td>\n",
              "      <td>0.364532</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0, 10519)\\t0.36615789703089635\\n  (0, 16751...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44257</th>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48</td>\n",
              "      <td>0.040268</td>\n",
              "      <td>0.310345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0, 18322)\\t0.501446310561246\\n  (0, 9946)\\t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44258</th>\n",
              "      <td>0.053247</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54</td>\n",
              "      <td>0.040268</td>\n",
              "      <td>0.379310</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0, 9747)\\t0.5988249079618629\\n  (0, 23970)\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44259</th>\n",
              "      <td>0.083117</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.060403</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0, 7474)\\t0.4857924594516143\\n  (0, 17094)\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44260</th>\n",
              "      <td>0.040260</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43</td>\n",
              "      <td>0.033557</td>\n",
              "      <td>0.314655</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0, 15843)\\t0.5678698270937518\\n  (0, 9794)\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44261</th>\n",
              "      <td>0.055844</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>57</td>\n",
              "      <td>0.046980</td>\n",
              "      <td>0.348276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0, 24605)\\t0.4359189752165128\\n  (0, 23411)...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44262 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       body_len    punct%  char_count  word_count  word_density  \\\n",
              "0      0.050649  0.073333          53    0.046980      0.306897   \n",
              "1      0.063636  0.000000          66    0.067114      0.283820   \n",
              "2      0.064935  0.236667          65    0.053691      0.369906   \n",
              "3      0.041558  0.000000          45    0.040268      0.275862   \n",
              "4      0.038961  0.093333          41    0.026846      0.364532   \n",
              "...         ...       ...         ...         ...           ...   \n",
              "44257  0.045455  0.000000          48    0.040268      0.310345   \n",
              "44258  0.053247  0.000000          54    0.040268      0.379310   \n",
              "44259  0.083117  0.000000          80    0.060403      0.448276   \n",
              "44260  0.040260  0.000000          43    0.033557      0.314655   \n",
              "44261  0.055844  0.000000          57    0.046980      0.348276   \n",
              "\n",
              "       punctuation_count  title_word_count  upper_case_word_count  \\\n",
              "0               0.035714               0.0                    0.0   \n",
              "1               0.000000               0.0                    0.0   \n",
              "2               0.142857               0.0                    0.0   \n",
              "3               0.000000               0.0                    0.0   \n",
              "4               0.035714               0.0                    0.0   \n",
              "...                  ...               ...                    ...   \n",
              "44257           0.000000               0.0                    0.0   \n",
              "44258           0.000000               0.0                    0.0   \n",
              "44259           0.000000               0.0                    0.0   \n",
              "44260           0.000000               0.0                    0.0   \n",
              "44261           0.000000               0.0                    0.0   \n",
              "\n",
              "                                                       0  \n",
              "0        (0, 24068)\\t0.3653518284793476\\n  (0, 24886)...  \n",
              "1        (0, 15364)\\t0.3034613181724768\\n  (0, 12877)...  \n",
              "2        (0, 5116)\\t0.30299181479990983\\n  (0, 21005)...  \n",
              "3        (0, 5080)\\t0.5618642544312047\\n  (0, 19776)\\...  \n",
              "4        (0, 10519)\\t0.36615789703089635\\n  (0, 16751...  \n",
              "...                                                  ...  \n",
              "44257    (0, 18322)\\t0.501446310561246\\n  (0, 9946)\\t...  \n",
              "44258    (0, 9747)\\t0.5988249079618629\\n  (0, 23970)\\...  \n",
              "44259    (0, 7474)\\t0.4857924594516143\\n  (0, 17094)\\...  \n",
              "44260    (0, 15843)\\t0.5678698270937518\\n  (0, 9794)\\...  \n",
              "44261    (0, 24605)\\t0.4359189752165128\\n  (0, 23411)...  \n",
              "\n",
              "[44262 rows x 9 columns]"
            ]
          },
          "execution_count": 914,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnPJPIP0JlW7"
      },
      "source": [
        "## Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6l3SR67JlW8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VtSXrZHJlW8"
      },
      "outputs": [],
      "source": [
        "X = bow1\n",
        "y = df_train['is_sarcastic']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.20,\n",
        "                                                    random_state = 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ws-pkaEJlW8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDC5KTNDJlW8"
      },
      "source": [
        "### Building ML Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf7e3zLAJlW8",
        "outputId": "3d3e0b87-0602-4956-d515-72bd91ea18c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_jobs=-1)"
            ]
          },
          "execution_count": 917,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model1 = RandomForestClassifier(n_jobs=-1)\n",
        "model1.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV_k8JlgJlW9"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PFAm5F4JlW9"
      },
      "outputs": [],
      "source": [
        "#test_data=bow2\n",
        "#bow2 = cv.fit_transform(x2)\n",
        "#data = cv.transform(df_test['headline']).toarray()\n",
        "y_pred=model1.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo28BE-iJlW9",
        "outputId": "2f8958d8-87c0-4d5e-836a-adc6837f6262"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
            ]
          },
          "execution_count": 919,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE3hl1XLJlW-",
        "outputId": "595e3a35-14b7-411c-c431-3303f1ec82b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
            ]
          },
          "execution_count": 920,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p54bQuQDJlW-",
        "outputId": "d82521ae-c65d-4b59-9d68-a29daf1a60a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy... 0.9999717585924482\n",
            "Test accuracy 0.9094092398057155\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('Training accuracy...', accuracy_score(y_train, model1.predict(X_train)))\n",
        "print('Test accuracy', accuracy_score(y_test,model1.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TANnAUiLJlW-",
        "outputId": "1ef1e35c-59f4-4af3-ecac-6a1aee83d86e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[4510,  256],\n",
              "       [ 546, 3541]], dtype=int64)"
            ]
          },
          "execution_count": 922,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmjW5innJlW_"
      },
      "source": [
        " ## Execute this model of test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5XY29AuJlW_",
        "outputId": "0fc0915a-b57f-46a1-f392-582ada520688"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'new_headline2'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'new_headline2'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4324/1938678459.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#y_pred_test=model1.predict(x2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new_headline2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'new_headline2'"
          ]
        }
      ],
      "source": [
        "#y_pred_test=model1.predict(x2)\n",
        "data = cv.transform(df_test['new_headline2']).toarray()\n",
        "y_pred_test=model1.predict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTPnhk6EJlW_",
        "outputId": "3dc8408c-8563-4df4-8eec-88e6bdf1489c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
            ]
          },
          "execution_count": 620,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmxG1EaTJlW_"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(y_pred_test, columns=['prediction'])\n",
        "df.to_csv('e:y_pred_test.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLqdnW38JlXA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ2iUS4BJlXA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sarcasm Detection_dawood_after_feutcher.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}